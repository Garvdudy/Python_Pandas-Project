{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "937da923-ba58-4886-b90b-ada8f51076a6",
   "metadata": {},
   "source": [
    "# JSearch Project Using APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b988e55-008b-40c9-8ec1-43f840a29a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1001812d-6330-4654-9010-0e099981cb7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analyst - Governance\n",
      "Toronto\n",
      "Full-time\n",
      "https://careers.teksystems.com/us/en/job/JP-005208487/Data-Analyst-Governance?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
      "Data Analyst - Governance\n",
      "\n",
      "Job Opportunity:\n",
      "• Opportunity of collaborating with one of Canadas top five banks focusing on data governance strategies underpinned by industry-leading processes established by the data governance team.\n",
      "• Chance to contribute to positioning the bank as a leader in aligning data governance initiatives with technology-driven business value in an environment of rapid growth and innovation.\n",
      "• Hybrid flexibility - good work/life balance\n",
      "\n",
      "Qualifications:\n",
      "\n",
      "The ideal candidate will possess a strong experience in data governance and data development including expertise with ETL processes Power BI or Microsoft Fabric. They will have excellent English language proficiency exceptional presentation abilities and be fluent in Spanish. Additionally they should showcase a proven capacity for self-prioritization and the ability to operate effectively with minimal supervision.\n",
      "• 10 years experience working as a sr contributor in a data focused team.\n",
      "• 5 years working with data governance data management frameworks cataloging CDEs and tracing / managing data lineage.\n",
      "• 3 years experience leading meetings and creating presentation decks for various technical business and risk / compliance audiences.\n",
      "• Skilled in summarizing and provides insights from complicated processes.\n",
      "• 2 years operational Technology Experience and understands the concepts of Technology Risk Resilience and Reliability.\n",
      "• 2 years experience IT operations or IT Risk This includes ServiceNow or other ITSM solutions.\n",
      "\n",
      "Education/ Certifications:\n",
      "\n",
      "- Certification in data or data management.\n",
      "\n",
      "- ITIL V3/V4 certification preferred.\n",
      "\n",
      "- Certification in risk management.\n",
      "\n",
      "- Bachelors degree in computer science or a related discipline.\n",
      "\n",
      "Project Overview:\n",
      "\n",
      "This role is ideal for a seasoned data analyst with expertise in delivering robust data solutions and repositories leveraging cutting-edge data governance technologies.\n",
      "\n",
      "The primary focus will be on defining the technology domain identifying authoritative global sources of technology data classifying data assets cataloguing critical data elements and their lineage and ensuring high standards of data quality.\n",
      "\n",
      "The role also requires a thorough understanding of regulatory requirements related to data governance supporting compliance with all regulatory and audit mandates.\n",
      "\n",
      "The technology data is centered on optimizing operations to mitigate risk enhance resilience and ensure reliability in technology management.\n",
      "\n",
      "Work Environment:\n",
      "• Schedule Hours: 9am-5pm Monday-Friday standard 37.5 hrs/week Possible OT\n",
      "• Hybrid/ Remote: Hybrid mostly open to fully remote 2 days a month. Thursdays\n",
      "\n",
      "Pay and Benefits\n",
      "\n",
      "The pay range for this position is $70.00 - $75.00/hr.\n",
      "\n",
      "Workplace Type\n",
      "\n",
      "This is a hybrid position in Toronto,ON.\n",
      "\n",
      "À propos de TEKsystems:\n",
      "\n",
      "Nous sommes partenaires dans la transformation. Nous aidons les clients à activer des idées et des solutions afin de profiter d’un nouveau monde d’opportunités. Nous sommes une équipe solide de 80 000 personnes, nous travaillons avec plus de 6 000 clients, dont 80 % faisant partie du Fortune 500, partout en Amérique du Nord, en Europe et en Asie. En tant que chefs de file de l’industrie des services technologiques complets, des services aux talents et des applications du monde réel, nous travaillons avec des leaders progressistes pour favoriser le changement. C’est le pouvoir d’un vrai partenariat. TEKsystems est une société du groupe Allegis.\n",
      "\n",
      "About TEKsystems:\n",
      "\n",
      "We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.\n",
      "\n",
      "The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.\n",
      "==============================\n",
      "Data Analyst\n",
      "Toronto\n",
      "Contractor\n",
      "https://jobs.insightglobal.com/find_a_job/ontario/job-404411/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
      "Insight Global is looking for a Business Analyst to join a leading banking client downtown Toronto.\n",
      "\n",
      "In this role, you will be responsible to help build new customer journeys and optimize existing journeys\n",
      "\n",
      "The successful candidate will be required to work in office 1-2x/week.\n",
      "\n",
      "We are a company committed to creating diverse and inclusive environments where people can bring their full, authentic selves to work every day. We are an equal opportunity/affirmative action employer that believes everyone matters. Qualified candidates will receive consideration for employment regardless of their race, color, ethnicity, religion, sex (including pregnancy), sexual orientation, gender identity and expression, marital status, national origin, ancestry, genetic factors, age, disability, protected veteran status, military or uniformed service member status, or any other status or characteristic protected by applicable laws, regulations, and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or recruiting process, please send a request to HR@insightglobal.com.\n",
      "\n",
      "To learn more about how we collect, keep, and process your private information, please review Insight Global's Workforce Privacy Policy: https://insightglobal.com/workforce-privacy-policy/ .\n",
      "==============================\n",
      "Data Analyst (Power BI/SQL Developer)\n",
      "Toronto\n",
      "Full-time\n",
      "https://ca.indeed.com/viewjob?jk=167d665ec46cd7de&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\n",
      "Choose a workplace that empowers your impact.\n",
      "Join a global workplace where employees thrive. One that embraces diversity of thought, expertise and experience. A place where you can personalize your employee journey to be — and deliver — your best.\n",
      "\n",
      "We are a purpose-driven, dynamic and sustainable pension plan. An industry leading global investor with teams in Toronto to London, New York, Singapore, Sydney and other major cities across North America and Europe. We embody the values of our 600,000+ members, placing their best interests at the heart of everything we do.\n",
      "\n",
      "Join us to accelerate your growth & development, prioritize wellness, build connections, and support the communities where we live and work.\n",
      "\n",
      "Don’t just work anywhere — come build tomorrow together with us.\n",
      "\n",
      "Know someone at OMERS or Oxford Properties? Great! If you're referred, have them submit your name through Workday first. Then, watch for a unique link in your email to apply.\n",
      "\n",
      "We are seeking for a highly skilled and motivated Data Analyst to join our Pension Products & Technology team in Toronto. The ideal candidate will have at least 5 years of hands-on experience in data analysis, leveraging tools such as Power BI, SQL, Python, and Excel to deliver advanced analytics, develop insightful dashboards, and create impactful reports that drive data-informed decisions. This is a fantastic opportunity for a Data Analyst to work with cutting-edge data analytical tools while being part of a dynamic Pension Data team that fosters collaboration, encourages innovation, and supports professional growth.\n",
      "\n",
      "As a member of this team, you will be responsible for:\n",
      "Data Collection & Integration\n",
      "\n",
      "Collect data from multiple sources, such as databases, APIs, or external systems.\n",
      "\n",
      "Integrate data from various sources, ensuring that it’s accurate, consistent, and complete.\n",
      "\n",
      "Manage large datasets and ensure the proper storage and retrieval processes are in place.\n",
      "\n",
      "Data Cleaning and Preprocessing\n",
      "\n",
      "Clean and preprocess raw data to remove errors, inconsistencies, or duplicate entries.\n",
      "\n",
      "Transform data into a structured format suitable for analysis, applying necessary formatting or aggregation techniques.\n",
      "\n",
      "Validate data to ensure its accuracy and integrity before performing analysis.\n",
      "\n",
      "Data Analysis & Interpretation\n",
      "\n",
      "Analyze data to identify trends, patterns, and relationships that can provide insights.\n",
      "\n",
      "Use statistical methods and predictive models to address business problems and support decision-making.\n",
      "\n",
      "Perform descriptive and exploratory analysis to understand key metrics and KPIs.\n",
      "\n",
      "Reporting & Visualization\n",
      "\n",
      "Create reports, dashboards, and visualizations to communicate data insights clearly and effectively using Power BI and Excel.\n",
      "\n",
      "Automate recurring reports to improve efficiency and ensure timely delivery of insights.\n",
      "\n",
      "Present findings to stakeholders with clear, actionable insights through reports and presentations.\n",
      "\n",
      "Collaboration & Communication\n",
      "\n",
      "Collaborate with cross-functional teams, including business stakeholders, product teams, and development engineering teams, to understand data requirements and deliver insights.\n",
      "\n",
      "Translate complex data into understandable terms for non-technical stakeholders.\n",
      "\n",
      "Work closely with team members to define key performance indicators (KPIs) and measurement frameworks.\n",
      "\n",
      "Continuous Learning and Improvement\n",
      "\n",
      "Identify opportunities to improve existing data processes and analytical techniques.\n",
      "\n",
      "Keep up with the latest trends and best practices in data analysis, visualization, and tools.\n",
      "\n",
      "Experiment with new methods and tools to enhance the quality and speed of data analysis.\n",
      "\n",
      "Data Governance & Quality Assurance\n",
      "\n",
      "Ensure data security, privacy, and compliance with regulations during the collection and analysis process.\n",
      "\n",
      "Implement processes for quality control to ensure the accuracy and reliability of data.\n",
      "\n",
      "Monitor and audit data sources for consistency and potential issues over time.\n",
      "\n",
      "Ad-Hoc SQL Query Development & Analysis\n",
      "\n",
      "Develop SQL Queries & Conduct ad-hoc analysis to address immediate data requests and to provide urgent data insights.\n",
      "\n",
      "Documentation & Knowledge Sharing\n",
      "\n",
      "Document analysis methods, assumptions, and results for transparency and reproducibility.\n",
      "\n",
      "Share insights and learnings with the broader team, contributing to a knowledge-sharing culture.\n",
      "\n",
      "To succeed in this role, you have:\n",
      "Bachelor’s degree in computer engineering, Computer Science, Information Technology, or a related field (or equivalent experience).\n",
      "\n",
      "5 years of hands-on experience in Data analysis, Power BI development and SQL Query Development.\n",
      "\n",
      "Strong proficiency in Power BI, including Power Query, Power BI Service, and Power BI Desktop.\n",
      "\n",
      "Expertise in DAX (Data Analysis Expressions) for creating measures, calculated columns and complex DAX expressions.\n",
      "\n",
      "Must have experience building semantic data models in Power BI\n",
      "\n",
      "Experience working with relational databases and data warehousing concepts.\n",
      "\n",
      "Proficiency in SQL and Python for querying and transforming data.\n",
      "\n",
      "A team player and motivated self-starter\n",
      "\n",
      "Strong problem-solving and critical-thinking skills.\n",
      "\n",
      "Experience with Azure Data Services (Azure SQL Database, Azure Data Factory)\n",
      "\n",
      "Excellent communication and presentation skills.\n",
      "\n",
      "Attention to detail and a commitment to accuracy.\n",
      "\n",
      "Ability to manage multiple projects and meet deadlines.\n",
      "\n",
      "Strong Understanding of DB Pension Knowledge is an asset.\n",
      "\n",
      "We believe that time together in the office is important for OMERS and Oxford, the strength of our employees, and the work we do for our pension members. In delivering on our pension promise, keeping us connected to our work and each other, our flexible hybrid work guideline requires teams to come in to the office 1+ days per week\n",
      "\n",
      "As one of Canada’s largest defined benefit pension plans, our people-first culture is at its best when our workforce reflects the communities where we live and work — and the members we proudly serve.\n",
      "\n",
      "From hire to retire, we are an equal opportunity employer committed to an inclusive, barrier-free recruitment and selection process that extends all the way through your employee experience. This sense of belonging and connection is cultivated up, down and across our global organization thanks to our vast network of Employee Resource Groups with executive leader sponsorship, our Purpose@Work committee and employee recognition programs.\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Define the API endpoint\n",
    "url = \"https://jsearch.p.rapidapi.com/search\"\n",
    "\n",
    "# Choose your job search parameters\n",
    "querystring = {\n",
    "    \"query\": \"Data Analyst in Toronto, Canada\",\n",
    "    \"page\": \"1\",\n",
    "    \"num_pages\": \"1\"\n",
    "}\n",
    "\n",
    "# Headers with your API key & host\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"f246462ff3msh697697611159483p188b74jsn11b570642f90\",  # Replace with your key if needed\n",
    "    \"X-RapidAPI-Host\": \"jsearch.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "# Convert response to JSON\n",
    "data = response.json()\n",
    "\n",
    "# Check the structure of the result\n",
    "for job in data['data'][:3]:  # show top 3 results\n",
    "    print(job['job_title'])\n",
    "    print(job['job_city'])\n",
    "    print(job['job_employment_type'])\n",
    "    print(job['job_apply_link'])\n",
    "    print(job['job_description'])\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "718ae0b2-97cd-4716-91f2-43fb336cf031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data extracted and saved to 'toronto_data_analyst_jobs.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# API URL and headers\n",
    "url = \"https://jsearch.p.rapidapi.com/search\"\n",
    "querystring = {\n",
    "    \"query\": \"data analyst\",\n",
    "    \"page\": \"1\",\n",
    "    \"num_pages\": \"1\",\n",
    "    \"location\": \"Toronto, ON\"\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"x-rapidapi-key\": \"f246462ff3msh697697611159483p188b74jsn11b570642f90\",\n",
    "    \"x-rapidapi-host\": \"jsearch.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "# Request data\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "data = response.json()\n",
    "\n",
    "# Extract relevant fields\n",
    "jobs_list = []\n",
    "for job in data[\"data\"]:\n",
    "    job_info = {\n",
    "        \"Job Title\": job.get(\"job_title\"),\n",
    "        \"Company\": job.get(\"employer_name\"),\n",
    "        \"Location\": job.get(\"job_city\", \"\") + \", \" + job.get(\"job_country\", \"\"),\n",
    "        \"Employment Type\": job.get(\"job_employment_type\"),\n",
    "        \"Posted Date\": job.get(\"job_posted_at_datetime_utc\"),\n",
    "        \"Job Description\": job.get(\"job_description\")[:300] + \"...\",\n",
    "        \"Apply Link\": job.get(\"job_apply_link\")\n",
    "    }\n",
    "    jobs_list.append(job_info)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(jobs_list)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"toronto_data_analyst_jobs.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data extracted and saved to 'toronto_data_analyst_jobs.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
